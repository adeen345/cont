Continuous Integration
Continuous Integration, or CI, is used to automate the integration of code changes from multiple developers into a single main stream. Using a workflow whereby small changes are merged frequently, often many times per day, will reduce the number of merge conflicts.

This process is widespread in test-driven software development strategies. CI is often used to automatically compile the project and run tests on every code change to ensure that the build remains stable and prevent regressions in functionality.

Continuous Delivery
Continuous Delivery is an extension of Continuous Integration. Once the changes have been merged into the main stream, a Continuous Delivery system automatically packages the application and prepares it for deployment. This helps avoid human error when packaging the application.

Continuous Deployment
Continuous Deployment is an extension of Continuous Delivery. The goal of Continuous Deployment is to deploy and release software to customers frequently and safely. The strategy commonly involves automatically deploying to a test (also known as staging) environment first to validate the deployment package and software changes. Once validated, it can automatically deploy to the live (also known as production) environment for customers.


Development Environments
Every development team prior to releasing their new features or changes needs to verify that the code they do release is not going to cause any issues or bugs. In order to achieve this, they normally set up multiple environments for different ways to test and verify.  A common practice is for teams to have a developer environment, a UAT or QA environment, and a staging environment. The main purpose of this flow is to find any potential issues that may arise due to changes or new features being added to the codebase. The more ways to test the changes the less likely bugs will be introduced.

Staging:
The staging environment should mimic your production environment. The reason for this is because you want to test the code in an environment that matches what you have in production. This allows teams to spot or find any potential issues prior to them getting to production. The closer the staging environment is to your production, the more accurate your testing is going to be. Staging environments can also be used for testing and verifying new features and allow other teams including QA or stakeholders to see and use those features as a pre-trial. Staging should also cover all areas of the architecture of the application including the database and any other services that may be required. Areas that benefit from staging environments include:
New Features:
Developers submitting new features along with feature flags for turning them on and off should always do a testing round in a staging environment. They allow teams to verify that the feature works, it can be turned on and off via configuration flags and also that it does not break or interfere with existing functionality.
Testing:
As the staging environment mimics your production environment, it's also a great place to run tests. QA teams will normally use it to verify new features, configuration changes or software updates/patching. The types of testing covered will be Unit testing, Integration testing and performance testing. All except performance testing can also be carried out in production. Performance can also be completed in production but only at specific times - usually out of hours as it will have a drastic effect on the user experience.
Sometimes it is not always feasible to have an exact replication either due to costs or time. Certain areas can be cut back - for example, if your service is load balanced on 10 virtual machines in production, you could still have 4 virtual machines in staging. The underlying architecture is the same but the overall performance may be different.
Migrations:
Staging is a perfect place to test and verify data migrations. Snapshots can be taken from production and used to test your migration scripts to confirm your changes will not break anything. If in the case it does cause an issue, you simply rollback and try again. Doing something like a migration in production is extremely risky and error-prone.
Configuration Changes:
Configuration can also cause headaches for teams, especially in a large cloud-based architecture. Having a staging environment will allow you to spot any potential issues or bottlenecks.
Production:
Production is live. It's out there for people to see and/or interact with. Any issues or problems you may have had should have been caught and fixed in the staging environment. The staging area gives the team a safety net to catch these possible issues. Any code that is deployed to production should have been tested and verified before the deployment itself. 
Downtime:
Downtime for any service especially customer facing will most likely be revenue impacting. If customers can not access or use your website or app to its full capabilities, it will most likely have a cost involved. Take for example an e-commerce company that allows users to buy goods and services online. If they release a new feature to their shopping cart which actually breaks the payment process, this will have an impact on customers not being able to buy goods online.
Vulnerabilities:
Cyber-security should also play a big role in what gets released in production. Any updates to software such as patching or moving to the latest version should be checked and verified. This is also the same rule for not upgrading software when critical updates are released.
Reputation:
Downtime or issues in production is damaging for a company as it does not instill confidence in end users. If something is down or broken it can cause the company to lose potential customers.


COMMAND LINE:
cd //change directory
touch //create a file
mkdir //make a folder
code filename //open file in vscode
dir //list of folders and files
pwd//path of current dir
ls -l//list all files or folders
mv filetoBEMOVED WHERETObeMoved
cat fileName //too check content of a file
wc fileName -w//word count of a file

Pipes:
allow you to pass the output of one command to be used as the input of another
cat file1 file2 | wc -w //returns wordcount of both files added

Redirection:
You can change the standard input and output
Three types:
Standard input 0
standard output 1
sandard error 2

input:
cat > input.txt //this will allow you to save user input to a file ctrl+D to indicate end of the file
cat < input.txt //output contents

output:
send output of a command to a text file
ls -l > output.txt //will send output of ls -l to output.txt

error:
ls -l /bin/usr 2> error.txt //2> for standard error

GREP:
global regular expression print
searching across files and folders as well as the content of files

to find names that begin with sam:
grep sam names.txt //ooks for names in names.txt. to ignore case sensitivity: grep -i sam names.txt

to get exact match:
grep -w Sam names.txt //ony returns sam

ls /bin | grep zip //all zip files in bin directory 

You can connect with github via https or shell:
using https: You need a personal access token for this.

using shell: You can sign in to your github in the shell or use public and private keys.


To clone a repo into your machine:
git init
git clone httpsAddress //clone used for first time. pull used after for pulling changes

From working directory, you send file to a staging area, then commit it and then push to a remote repo

git status //tells you about changes that need to be committed
git add //tells git to track a file
git restore --stage * //to unstage files
git commit -m "" //commit to local repo

git checkout -B name //to create a new branch and switch to it
git branch name //create but dont switch
git branch //check which branch you are on
git remote -v//to check url of repo where changes are committed or pulled from

git remote add origin httpsAddress
git push -u origin BranchName //-u means upstream updates only
git pull //to pull changes made to repo to local machine
pull request is for merging branches

git log --pretty=oneline //shows commits in one line each

Resolving conflicts
Conflicts will normally occur when you try to merge a branch that may have competing changes. Git will normally try to automatically merge (auto-merge), but in the case of a conflict it will need some confirmation, the competing changes need to be resolved by the end user. This process is called merging or rebasing. 
The developer must look at the changes on the server and the changes on their local and validate which changes should be resolved.
A merge conflict example is when two developers are working on their own dependent branches. Both developers are working on the same file called Feature.js. Each of their tasks is to add a new feature to an existing method. Developer 1 has a branch called feature1 and developer 2 has a branch called feature2. 
Developer 1 pushes the code with the changes to the remote repository. Developer 2 pushes their changes.


A hidden folder .git is located in each project. This folder keeps track of all changes.It keeps a special
pointer called head which points to the current branch

cd .git
cat HEAD //tell you which branch you are currently on.

git diff //tells you what changer were made across branches and commits
It compares previous version of file with current one to find any differences
Makes comparisons against files on your local repo
git diff HEAD filename //if before commit it shows you what you have cchanged since last commit.
get id from git log. then do git diff id1 id2 to compare changes across commits
to compare across branches: git diff branch1 branch2


git blame:
git blame filename //returns a list of all changes on the file along with the date and name of person

git blam -L 5,15 filename //return changes from line 5 to 15

you can copy the id from git blame and do git log -p id to see details of changes


Forking
In previous lessons, you have touched on workflows such as branching and how they can be used to 
simplify a process for a team. Forking is another type of workflow. The key difference between branching 
and forking is that the workflow for forking creates a new repository entirely. Branching cuts a new 
branch from the same repository each time and each member of the team works on the single repository.
In order to get the feature back into the original repository, he will need to create a PR as normal but instead of comparing with the main branch, it needs to be compared with the original repository. Essentially the two repositories are compared against each other. The owner of the original repository can then review the PR and choose to accept of decline the new feature.
 
